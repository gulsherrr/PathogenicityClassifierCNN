This repository documents my first complete deep-learning genomics project: building an end-to-end pipeline that predicts whether a genetic variant is benign or pathogenic using only its 201-bp DNA sequence context.
What began as a learning exercise evolved into a full experimental workflow spanning data engineering, sequence encoding, model building, GPU training, and evaluation across multiple chromosomes.

The final model, BetterCNNv2, trained on variants from chromosomes 1, 2, 3, and 22, achieved a validation AUROC of 0.81, demonstrating that it successfully captures sequence-level patterns associated with pathogenicity.

Day 1 — Environment Setup

Set up the local development environment:
Anaconda Prompt, project folders (data/, notebooks/, src/, reports/), Git initialization, and JupyterLab configuration.

Day 2 — File Handling & Basic Plotting

Learned foundational workflow skills: CSV reading/writing, file paths, project structure, and simple exploratory plots.
Gained familiarity with how data flows through a ML project.

Day 3 — One-Hot Encoding & Sequence Features

Practiced NumPy warm-ups.
Generated synthetic DNA sequences, computed GC% content, visualized a GC histogram, and created a one-hot encoding heatmap.
Loaded a small fake variant dataset to test encoding and plotting tools.

Day 4 — First Real Pipeline Components

Loaded a fake variant dataset, implemented integer-vectorized encoding, built a loop-free one-hot encoder, stacked sequences into PyTorch-ready tensors, and performed a stratified train/validation/test split.
Computed a transition vs transversion indicator, preparing the pipeline for real data.

Day 5 — First 1D Convolutional Neural Network

Installed PyTorch, created Dataset and DataLoader classes, and built a simple 1D-CNN.
Trained and validated the model locally, producing loss curves, accuracy curves, a confusion matrix, probability distributions, and prediction tables.

Day 6 — Full Real-Data Pipeline on Chromosome 22

Upgraded the entire workflow to operate on real human variation data (ClinVar + chr22 FASTA).
Pipeline:
download → clean → extract sequence windows → one-hot encode → split → model → evaluation
Achieved a non-random AUROC on validation data, indicating real biological signal.

Day 7 — Larger Windows & Deeper CNN

Constructed 201-bp windows, built a deeper 3-layer CNN with dropout and max-pooling, and trained it for 20 epochs.
Generated real training and validation curves and computed a test AUROC, showing that the model genuinely learned sequence-pattern determinants of pathogenicity.

Day 8 — GPU Training on Google Colab (Multi-Chromosome)

Migrated the project to Google Colab for GPU acceleration.
Loaded balanced variant windows from chromosomes 1, 2, 3, and 22 (~400k samples).
Built BetterCNNv2, a deeper 1D-CNN with larger filters and more channels.
Trained for 15 epochs and produced clean training-loss and validation-AUROC curves.
Final validation AUROC: 0.81.

Key Features

End-to-end variant classification pipeline

DNA sequence extraction from multiple chromosomes

201-bp window context per variant

Custom one-hot encoding implementation

PyTorch Datasets, DataLoaders, and training loops

Custom multi-layer 1D-CNN architectures

Balanced sampling of pathogenic vs benign variants

GPU-accelerated training on real genomic data

Clear evaluation metrics (loss, AUROC, prediction distributions)
